### What Do You Know If You Are Ignorant?

### Benford's Law

- **Core insight**: When truly ignorant about a physical quantity, the probability of the first digit being _d_ is not uniform
- **Formula**: P(first digit = d) = log₁₀(1 + 1/d)
- **Key result**: P(first digit = 1) ≈ 30.1%, P(first digit = 9) ≈ 4.6%
- **Principle**: Ignorance corresponds to scale invariance - predictions shouldn't depend on arbitrary units
- **Implication**: Uniform distributions don't always represent "ignorance"

### Unit Invariance

- True ignorance means predictions are independent of measurement units
- Leads to logarithmic probability distributions over scales
- Probability proportional to length on logarithmic scale

## Inferring Causation

### Likelihood Equivalence Problem

- **Definition**: Two models are likelihood-equivalent if they can produce identical probability distributions
- **Example**: A→B vs B→A models can be statistically indistinguishable
- **Classical limitation**: Non-Bayesian methods cannot distinguish between such models

### Bayesian Advantage

- **Key insight**: Bayesian methods can distinguish likelihood-equivalent models through priors
- **Controversial position**: Author argues against "prior equivalence" orthodoxy
- **Philosophy**: Priors should reflect genuine assumptions, not be artificially constrained

### Practical Approach

- Use informative priors that encode real beliefs about causal relationships
- Don't artificially restrict priors to make causation uninferable
- Bayesian inference can legitimately infer causal direction from data

## General Themes

### Modeling Ignorance

- True ignorance often requires non-uniform distributions
- Scale invariance is a key principle for representing ignorance
- Question assumptions about what constitutes "uninformative" priors

### Bayesian vs Classical Methods

- Bayesian methods offer advantages in causal inference
- Historical statistical methods sometimes used flawed approaches
- Proper Bayesian treatment can solve problems that classical methods struggle with

### Philosophical Points

- Challenge orthodoxies about "objective" priors
- Priors should reflect genuine knowledge states, not artificial constraints
- Causation can be inferred from data when approached correctly